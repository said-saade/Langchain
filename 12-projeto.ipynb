{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores.chroma import Chroma\n",
    "\n",
    "from langchain_community.document_loaders.pdf import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 16 0 (offset 0)\n",
      "Ignoring wrong pointing object 18 0 (offset 0)\n",
      "Ignoring wrong pointing object 20 0 (offset 0)\n",
      "Ignoring wrong pointing object 22 0 (offset 0)\n",
      "Ignoring wrong pointing object 42 0 (offset 0)\n",
      "Ignoring wrong pointing object 50 0 (offset 0)\n",
      "Ignoring wrong pointing object 52 0 (offset 0)\n",
      "Ignoring wrong pointing object 54 0 (offset 0)\n",
      "Ignoring wrong pointing object 56 0 (offset 0)\n",
      "Ignoring wrong pointing object 58 0 (offset 0)\n",
      "Ignoring wrong pointing object 70 0 (offset 0)\n",
      "Ignoring wrong pointing object 72 0 (offset 0)\n",
      "Ignoring wrong pointing object 89 0 (offset 0)\n",
      "Ignoring wrong pointing object 91 0 (offset 0)\n",
      "Ignoring wrong pointing object 103 0 (offset 0)\n",
      "Ignoring wrong pointing object 108 0 (offset 0)\n",
      "Ignoring wrong pointing object 149 0 (offset 0)\n",
      "Ignoring wrong pointing object 155 0 (offset 0)\n",
      "Ignoring wrong pointing object 158 0 (offset 0)\n",
      "Ignoring wrong pointing object 160 0 (offset 0)\n",
      "Ignoring wrong pointing object 163 0 (offset 0)\n",
      "Ignoring wrong pointing object 165 0 (offset 0)\n"
     ]
    }
   ],
   "source": [
    "caminhos = [\n",
    "    \"files/apostila.pdf\",\n",
    "    \"files/LLM.pdf\",\n",
    "    ]\n",
    "\n",
    "paginas = []\n",
    "for caminho in caminhos:\n",
    "    loader = PyPDFLoader(caminho)\n",
    "    paginas.extend(loader.load())\n",
    "\n",
    "recur_split = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=100,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "documents = recur_split.split_documents(paginas)\n",
    "\n",
    "for i, doc in enumerate(documents):\n",
    "    doc.metadata['source'] = doc.metadata['source'].replace('arquivos/', '')\n",
    "    doc.metadata['doc_id'] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "diretorio = 'arquivos/chat_retrieval_db'\n",
    "\n",
    "embeddings_model = OpenAIEmbeddings()\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embeddings_model,\n",
    "    persist_directory=diretorio\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.retrieval_qa.base import RetrievalQA\n",
    "\n",
    "chat_chain = RetrievalQA.from_chain_type(\n",
    "    llm=chat,\n",
    "    retriever=vectordb.as_retriever(search_type='mmr'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'O que é Hugging Face e como faço para acessá-lo?',\n",
       " 'result': 'Hugging Face é uma empresa e uma comunidade que desenvolve ferramentas e modelos de aprendizado de máquina, especialmente focados em processamento de linguagem natural (NLP). Eles são conhecidos por sua biblioteca Transformers, que facilita o uso de modelos pré-treinados para tarefas como tradução, geração de texto e muito mais.\\n\\nPara acessar o Hugging Face, você pode visitar o site oficial (huggingface.co) onde encontrará uma variedade de recursos, incluindo documentação, modelos e tutoriais. Além disso, você pode instalar a biblioteca Transformers em seu ambiente Python utilizando o comando:\\n\\n```bash\\npip install transformers\\n```\\n\\nIsso permitirá que você comece a utilizar os modelos disponíveis na plataforma.'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pergunta = \"O que é Hugging Face e como faço para acessá-lo?\"\n",
    "chat_chain.invoke({\"query\": pergunta})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "chain_prompt = PromptTemplate.from_template(\n",
    "\"\"\"Utilize o contexto fornecido para responder a pergunta ao final. \n",
    "Se você não sabe a resposta, apenas diga que não sabe e não invente uma resposta.\n",
    "Utilize três frases no máximo, mantenha a resposta concisa.\n",
    "\n",
    "Contexto: {context}\n",
    "\n",
    "Pergunta: {question}\n",
    "\n",
    "Resposta:\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_chain = RetrievalQA.from_chain_type(\n",
    "    llm=chat,\n",
    "    retriever=vectordb.as_retriever(search_type=\"mmr\"),\n",
    "    chain_type_kwargs={\"prompt\":chain_prompt},\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face é uma plataforma que oferece modelos de código aberto para processamento de linguagem natural, incluindo transformadores. Você pode acessá-la através do site oficial, onde pode encontrar e baixar diferentes modelos para usar em seus projetos. Além disso, a integração com frameworks como o MLflow facilita o uso desses modelos em ambientes Python.\n"
     ]
    }
   ],
   "source": [
    "pergunta = 'O que é Hugging Face e como faço para acessá-lo?'\n",
    "resposta = chat_chain.invoke({'query': pergunta})\n",
    "print(resposta['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Atualmente, requer um pouco mais de esforço para pegar um modelo de código aberto e começar a usá-lo, mas o progresso está ocorrendo muito rapidamente para torná-los mais acessíveis aos usuários. Na Databricks, por exemplo, fizemos melhorias em frameworks de código aberto como o MLflow para tornar muito fácil para alguém com um pouco de experiência em Python pegar qualquer modelo transformador da Hugging Face e usá-lo como um objeto Python. Muitas vezes, você pode encontrar um modelo de código aberto que resolve seu problema específico e que é várias ordens de grandeza menor que o ChatGPT, permitindo que você traga o modelo para seu ambiente e hospede-o você mesmo. Isso significa que você pode manter os dados sob seu controle para preocupações com privacidade e governança, além de gerenciar seus custos. Outra grande vantagem de usar modelos de código aberto é a capacidade de ajustá-los aos seus próprios dados', metadata={'doc_id': 75, 'page': 6, 'source': 'files/LLM.pdf'}),\n",
       " Document(page_content='E-BOOK Um guia compacto sobre Large Language Models (LLM)', metadata={'doc_id': 55, 'page': 0, 'source': 'files/LLM.pdf'}),\n",
       " Document(page_content='. Outras implementações notáveis de IA generativa incluem projetos como a geração de arte a partir de texto, áudio e vídeo, e certamente muitas outras novidades surgirão em breve.', metadata={'doc_id': 58, 'page': 1, 'source': 'files/LLM.pdf'}),\n",
       " Document(page_content='>>> hello()  \\nOlá Mundo!!!  \\n \\n \\n11.2 Parâmetros e a rgumentos  \\n \\n Parâmetros são as variáveis que podem ser incluídas nos parênteses das funções . Quando a \\nfunção é chamada são passados valores para essas variáveis. E sses valores são chamados \\nargumentos. O corpo da função pode utilizar essas variáveis, cujos valores podem modificar o \\ncomportamento da função.  \\n \\nExemplo:  Função para imprimir  o maior entre 2 valores  \\n \\ndef maior(x,y): \\n    if x>y: \\n        print(x) \\n    else: \\n        print(y) \\n \\n>>> maior(4,7)  \\n7', metadata={'doc_id': 46, 'page': 21, 'source': 'files/apostila.pdf'})]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resposta['source_documents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RetrievalQA] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"query\": \"O que é Hugging Face e como faço para acessá-lo?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain > chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"O que é Hugging Face e como faço para acessá-lo?\",\n",
      "  \"context\": \"Atualmente, requer um pouco mais de esforço para pegar um modelo de código aberto e começar a usá-lo, mas o progresso está ocorrendo muito rapidamente para torná-los mais acessíveis aos usuários. Na Databricks, por exemplo, fizemos melhorias em frameworks de código aberto como o MLflow para tornar muito fácil para alguém com um pouco de experiência em Python pegar qualquer modelo transformador da Hugging Face e usá-lo como um objeto Python. Muitas vezes, você pode encontrar um modelo de código aberto que resolve seu problema específico e que é várias ordens de grandeza menor que o ChatGPT, permitindo que você traga o modelo para seu ambiente e hospede-o você mesmo. Isso significa que você pode manter os dados sob seu controle para preocupações com privacidade e governança, além de gerenciar seus custos. Outra grande vantagem de usar modelos de código aberto é a capacidade de ajustá-los aos seus próprios dados\\n\\nE-BOOK Um guia compacto sobre Large Language Models (LLM)\\n\\n. Outras implementações notáveis de IA generativa incluem projetos como a geração de arte a partir de texto, áudio e vídeo, e certamente muitas outras novidades surgirão em breve.\\n\\n>>> hello()  \\nOlá Mundo!!!  \\n \\n \\n11.2 Parâmetros e a rgumentos  \\n \\n Parâmetros são as variáveis que podem ser incluídas nos parênteses das funções . Quando a \\nfunção é chamada são passados valores para essas variáveis. E sses valores são chamados \\nargumentos. O corpo da função pode utilizar essas variáveis, cujos valores podem modificar o \\ncomportamento da função.  \\n \\nExemplo:  Função para imprimir  o maior entre 2 valores  \\n \\ndef maior(x,y): \\n    if x>y: \\n        print(x) \\n    else: \\n        print(y) \\n \\n>>> maior(4,7)  \\n7\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain > chain:LLMChain > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Utilize o contexto fornecido para responder a pergunta ao final. \\nSe você não sabe a resposta, apenas diga que não sabe e não invente uma resposta.\\nUtilize três frases no máximo, mantenha a resposta concisa.\\n\\nContexto: Atualmente, requer um pouco mais de esforço para pegar um modelo de código aberto e começar a usá-lo, mas o progresso está ocorrendo muito rapidamente para torná-los mais acessíveis aos usuários. Na Databricks, por exemplo, fizemos melhorias em frameworks de código aberto como o MLflow para tornar muito fácil para alguém com um pouco de experiência em Python pegar qualquer modelo transformador da Hugging Face e usá-lo como um objeto Python. Muitas vezes, você pode encontrar um modelo de código aberto que resolve seu problema específico e que é várias ordens de grandeza menor que o ChatGPT, permitindo que você traga o modelo para seu ambiente e hospede-o você mesmo. Isso significa que você pode manter os dados sob seu controle para preocupações com privacidade e governança, além de gerenciar seus custos. Outra grande vantagem de usar modelos de código aberto é a capacidade de ajustá-los aos seus próprios dados\\n\\nE-BOOK Um guia compacto sobre Large Language Models (LLM)\\n\\n. Outras implementações notáveis de IA generativa incluem projetos como a geração de arte a partir de texto, áudio e vídeo, e certamente muitas outras novidades surgirão em breve.\\n\\n>>> hello()  \\nOlá Mundo!!!  \\n \\n \\n11.2 Parâmetros e a rgumentos  \\n \\n Parâmetros são as variáveis que podem ser incluídas nos parênteses das funções . Quando a \\nfunção é chamada são passados valores para essas variáveis. E sses valores são chamados \\nargumentos. O corpo da função pode utilizar essas variáveis, cujos valores podem modificar o \\ncomportamento da função.  \\n \\nExemplo:  Função para imprimir  o maior entre 2 valores  \\n \\ndef maior(x,y): \\n    if x>y: \\n        print(x) \\n    else: \\n        print(y) \\n \\n>>> maior(4,7)  \\n7\\n\\nPergunta: O que é Hugging Face e como faço para acessá-lo?\\n\\nResposta:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain > chain:LLMChain > llm:ChatOpenAI] [2.70s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Hugging Face é uma plataforma que fornece modelos de código aberto para tarefas de processamento de linguagem natural e aprendizado de máquina. Para acessá-lo, você pode visitar o site da Hugging Face e explorar sua biblioteca de modelos, que pode ser integrada facilmente em projetos com Python. Além disso, você pode usar frameworks como o MLflow para facilitar o uso desses modelos em seu ambiente.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Hugging Face é uma plataforma que fornece modelos de código aberto para tarefas de processamento de linguagem natural e aprendizado de máquina. Para acessá-lo, você pode visitar o site da Hugging Face e explorar sua biblioteca de modelos, que pode ser integrada facilmente em projetos com Python. Além disso, você pode usar frameworks como o MLflow para facilitar o uso desses modelos em seu ambiente.\",\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 78,\n",
      "                \"prompt_tokens\": 461,\n",
      "                \"total_tokens\": 539,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-4o-mini\",\n",
      "              \"system_fingerprint\": \"fp_72ed7ab54c\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-bad825db-68c7-4956-93d2-e8558df06e06-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 78,\n",
      "      \"prompt_tokens\": 461,\n",
      "      \"total_tokens\": 539,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-4o-mini\",\n",
      "    \"system_fingerprint\": \"fp_72ed7ab54c\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain > chain:LLMChain] [2.71s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"Hugging Face é uma plataforma que fornece modelos de código aberto para tarefas de processamento de linguagem natural e aprendizado de máquina. Para acessá-lo, você pode visitar o site da Hugging Face e explorar sua biblioteca de modelos, que pode ser integrada facilmente em projetos com Python. Além disso, você pode usar frameworks como o MLflow para facilitar o uso desses modelos em seu ambiente.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain] [2.71s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output_text\": \"Hugging Face é uma plataforma que fornece modelos de código aberto para tarefas de processamento de linguagem natural e aprendizado de máquina. Para acessá-lo, você pode visitar o site da Hugging Face e explorar sua biblioteca de modelos, que pode ser integrada facilmente em projetos com Python. Além disso, você pode usar frameworks como o MLflow para facilitar o uso desses modelos em seu ambiente.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RetrievalQA] [3.86s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n"
     ]
    }
   ],
   "source": [
    "from langchain.globals import set_debug\n",
    "\n",
    "set_debug(True)\n",
    "\n",
    "pergunta = 'O que é Hugging Face e como faço para acessá-lo?'\n",
    "resposta = chat_chain.invoke({'query': pergunta})\n",
    "\n",
    "set_debug(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face é uma empresa que desenvolve e mantém uma biblioteca popular de modelos de aprendizado de máquina, especialmente para tarefas de processamento de linguagem natural (NLP), incluindo Large Language Models (LLMs). A biblioteca mais conhecida da Hugging Face é o Transformers, que permite aos usuários utilizar e treinar modelos de linguagem sofisticados, como BERT, GPT-2 e muitos outros, que são fundamentais para diversas aplicações modernas em NLP.\n",
      "\n",
      "Além do processamento de linguagem, a Hugging Face também tem explorado outros aspectos da inteligência artificial generativa, como a geração de arte a partir de texto, áudio e vídeo. Isso reflete um movimento crescente em direção à criação de conteúdos multimídia por meio de IA, e espera-se que mais inovações surjam nesse campo.\n",
      "\n",
      "Para acessar o Hugging Face, você pode seguir estes passos:\n",
      "\n",
      "1. **Visite o site**: Acesse o site oficial da Hugging Face em [huggingface.co](https://huggingface.co).\n",
      "\n",
      "2. **Crie uma conta**: Se você desejar utilizar recursos como o armazenamento de modelos, colaboração e acesso a uma comunidade ativa, pode ser necessário criar uma conta.\n",
      "\n",
      "3. **Explore a biblioteca**: Navegue pelos modelos disponíveis, especialmente os LLMs e as implementações relacionadas à geração de conteúdo multimídia. A documentação é um recurso valioso.\n",
      "\n",
      "4. **Instale a biblioteca**: A biblioteca Transformers pode ser instalada via pip com o comando:\n",
      "   ```\n",
      "   pip install transformers\n",
      "   ```\n",
      "\n",
      "5. **Utilize os modelos**: Após a instalação, você pode começar a usar os modelos diretamente em seu código Python. A documentação fornece exemplos sobre como carregar e utilizar modelos específicos, incluindo os LLMs.\n",
      "\n",
      "6. **Ajuste os modelos**: Se você quiser adaptar um modelo ao seu próprio conjunto de dados, a Hugging Face oferece guias sobre como realizar o fine-tuning (ajuste fino) dos modelos, o que é especialmente útil para personalizar LLMs e outros modelos generativos para tarefas específicas.\n",
      "\n",
      "Assim como em uma função que recebe parâmetros e argumentos, onde o comportamento da função pode ser modificado conforme os valores passados, ao utilizar a biblioteca da Hugging Face, você pode modificar o comportamento dos modelos de IA ajustando os parâmetros e utilizando diferentes argumentos em suas chamadas, personalizando suas aplicações de acordo com suas necessidades específicas. Esses passos devem ajudá-lo a começar a usar os recursos oferecidos pela Hugging Face e a explorar o potencial dos Large Language Models, bem como outras inovações em inteligência artificial generativa.\n"
     ]
    }
   ],
   "source": [
    "chat_chain = RetrievalQA.from_chain_type(\n",
    "    llm=chat,\n",
    "    retriever=vectordb.as_retriever(search_type='mmr'),\n",
    "    chain_type='refine'\n",
    ")\n",
    "\n",
    "pergunta = 'O que é Hugging Face e como faço para acessá-lo?'\n",
    "resposta = chat_chain.invoke({'query': pergunta})\n",
    "print(resposta['result'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
